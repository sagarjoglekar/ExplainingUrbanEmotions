{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:23:12.708914Z",
     "start_time": "2017-10-05T17:23:11.578553Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from shapely import geometry\n",
    "import fiona\n",
    "import ipyparallel as ipp\n",
    "import geopandas as gpd\n",
    "from geopandas.geoseries import *\n",
    "from geopandas.tools import sjoin\n",
    "import shapefile\n",
    "from shapely.geometry import shape, Point\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory paths to the placepulse images and the augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:23:15.232032Z",
     "start_time": "2017-10-05T17:23:15.227587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgDir = \"/work/sagarj/Work/BellLabs/streetview/PPImages/\"\n",
    "AugDir = \"/work/sagarj/Work/BellLabs/streetview/USAEasternAugImages/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load placepulse vote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:23:24.678695Z",
     "start_time": "2017-10-05T17:23:21.909595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../streetview/votes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape file for localizing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:44:21.380341Z",
     "start_time": "2017-10-05T17:44:21.376199Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "londonShp = \"../shapeFiles/London_Ward_CityMerged.shp\"\n",
    "USAUAShp = \"../shapeFiles/cb_2016_us_ua10_500k.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:44:23.202584Z",
     "start_time": "2017-10-05T17:44:23.192844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'left_id', u'right_id', u'winner', u'left_lat', u'left_long',\n",
       "       u'right_lat', u'right_long', u'category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:23:49.391397Z",
     "start_time": "2017-08-16T09:23:49.370637Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if a lat long falls in the shapefile polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:23:49.805523Z",
     "start_time": "2017-08-16T09:23:49.797942Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(point, polygon):\n",
    "    if any(polygon.contains(point)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def checkPoly(point,polygonArray):\n",
    "    truths = [check(point , poly) for poly in polygonArray]\n",
    "    return any(truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary of localized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:21.608303Z",
     "start_time": "2017-08-16T09:23:50.284027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geometryDict = {}\n",
    "for idx, row in df.iterrows():\n",
    "    if row['left_id'] not in geometryDict:\n",
    "        p = Point(row['left_long'] , row['left_lat'])\n",
    "        geometryDict[row['left_id']] = p\n",
    "    if row['right_id'] not in geometryDict:\n",
    "        p = Point(row['right_long'] , row['right_lat'])\n",
    "        geometryDict[row['right_id']] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:21.617003Z",
     "start_time": "2017-08-16T09:25:21.610267Z"
    }
   },
   "outputs": [],
   "source": [
    "geometryDict[geometryDict.keys()[2]].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:23.928435Z",
     "start_time": "2017-08-16T09:25:21.618554Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa = gpd.read_file(\"../shapeFiles/cb_2016_us_ua10_500k.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:23.932669Z",
     "start_time": "2017-08-16T09:25:23.930382Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# london = gpd.read_file(\"../shapeFiles/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:23.961299Z",
     "start_time": "2017-08-16T09:25:23.934279Z"
    }
   },
   "outputs": [],
   "source": [
    "usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:30:51.775795Z",
     "start_time": "2017-08-16T09:30:51.771719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', len(usa['NAME10']))\n",
    "# print(usa['NAME10'])\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:23.965613Z",
     "start_time": "2017-08-16T09:25:23.962817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# us_selected_poly = ['Washington, DC--VA--MD' , 'New York--Newark, NY--NJ--CT' , 'Boston, MA--NH--RI' , 'Seattle, WA' , 'Portland, OR--WA' , \n",
    "#                     'Denver--Aurora, CO' , 'San Diego, CA' , 'San Francisco--Oakland, CA']\n",
    "us_selected_poly = ['Washington, DC--VA--MD' , 'New York--Newark, NY--NJ--CT' , 'Boston, MA--NH--RI']\n",
    "# london_selected_poly = ['Kensington and Chelsea','Westminster','Lambeth','Southwark','Hammersmith and Fulham','City of London','Islington','Camden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:24.066788Z",
     "start_time": "2017-08-16T09:25:24.064697Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# london_poly = [london[(london['NAME'] == k)]['geometry'] for k in london_selected_poly]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select specific images from polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:24.084285Z",
     "start_time": "2017-08-16T09:25:24.068357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_poly = [usa[(usa['NAME10'] == k)]['geometry'] for k in us_selected_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:24.256156Z",
     "start_time": "2017-08-16T09:25:24.086981Z"
    }
   },
   "outputs": [],
   "source": [
    "print(us_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:25:24.264822Z",
     "start_time": "2017-08-16T09:25:24.257652Z"
    }
   },
   "outputs": [],
   "source": [
    "checkPoly(geometryDict[geometryDict.keys()[1]] , us_poly )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.155144Z",
     "start_time": "2017-08-16T09:25:24.266377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_poly_Ids = [k for k in geometryDict if checkPoly(geometryDict[k],us_poly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.159169Z",
     "start_time": "2017-08-16T09:27:06.157012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# london_poly_Ids = [k for k in geometryDict if checkPoly(geometryDict[k],london_poly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.171519Z",
     "start_time": "2017-08-16T09:27:06.160687Z"
    }
   },
   "outputs": [],
   "source": [
    "len(us_poly_Ids)# ,len(london_poly_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.178574Z",
     "start_time": "2017-08-16T09:27:06.173073Z"
    }
   },
   "outputs": [],
   "source": [
    "us_poly_Ids[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group images by category as we plan to analyse based on dimension of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.184607Z",
     "start_time": "2017-08-16T09:27:06.180096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.581990Z",
     "start_time": "2017-08-16T09:27:06.186148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categoryPosts = {}\n",
    "for k in grouped.groups.keys():\n",
    "    categoryPosts[k] = grouped.get_group(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.587477Z",
     "start_time": "2017-08-16T09:27:06.583885Z"
    }
   },
   "outputs": [],
   "source": [
    "categoryPosts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.597021Z",
     "start_time": "2017-08-16T09:27:06.588988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DimensionDF = categoryPosts['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.608111Z",
     "start_time": "2017-08-16T09:27:06.598446Z"
    }
   },
   "outputs": [],
   "source": [
    "len(DimensionDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.617466Z",
     "start_time": "2017-08-16T09:27:06.609674Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = DimensionDF.groupby(['left_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.745350Z",
     "start_time": "2017-08-16T09:27:06.618967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VotesDistribution = numbers.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use truse skill to convert images from a particular dimension to an ordinal scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.769330Z",
     "start_time": "2017-08-16T09:27:06.747236Z"
    },
    "collapsed": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from trueskill import Rating , rate_1vs1 , rate\n",
    "def trueSkillRate(df):\n",
    "    skills = {}\n",
    "    ratingTable = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['left_id'] not in skills:\n",
    "            skills[row['left_id']] = Rating()\n",
    "        if row['right_id'] not in skills:\n",
    "            skills[row['right_id']] = Rating()\n",
    "            \n",
    "        if row['winner'] == 'left':\n",
    "            nRLeft , nRRight = rate_1vs1(skills[row['left_id']] , skills[row['right_id']] )\n",
    "            skills[row['left_id']] = nRLeft\n",
    "            skills[row['right_id']] = nRRight\n",
    "            touple = {row['left_id']:nRLeft , row['right_id'] : nRRight}\n",
    "            ratingTable.append(touple)\n",
    "        elif row['winner'] == 'right':\n",
    "            nRRight , nRLeft = rate_1vs1(skills[row['right_id']] , skills[row['left_id']] )\n",
    "            skills[row['left_id']] = nRLeft\n",
    "            skills[row['right_id']] = nRRight\n",
    "            touple = {row['left_id']:nRLeft , row['right_id'] : nRRight}\n",
    "            ratingTable.append(touple)\n",
    "        else:\n",
    "            nRRight , nRLeft = rate_1vs1(skills[row['right_id']] , skills[row['left_id']] , drawn = True )\n",
    "            skills[row['left_id']] = nRLeft\n",
    "            skills[row['right_id']] = nRRight\n",
    "            touple = {row['left_id']:nRLeft , row['right_id'] : nRRight}\n",
    "            ratingTable.append(touple)\n",
    "    \n",
    "    return skills , ratingTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to do stability analysis of the trueskill rating (can be used for other methods) to see how many samples change ordinal ratings as you consider more and more competetions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.815116Z",
     "start_time": "2017-08-16T09:27:06.772570Z"
    },
    "collapsed": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def stabilityAnalysis(df , start , end):\n",
    "    classflips = []\n",
    "    rootflips = []\n",
    "    numbers = DimensionDF.groupby('left_id')\n",
    "    TargetDf = numbers.filter(lambda x: len(x) > start)\n",
    "    depressingSkills , _ = trueSkillRate(TargetDf)\n",
    "    root1 = [k for k in depressingSkills if depressingSkills[k].mu > 25]\n",
    "    root2 = [k for k in depressingSkills if depressingSkills[k].mu < 25]\n",
    "\n",
    "    for i in range(start,end+1):\n",
    "        \n",
    "        TargetDf = numbers.filter(lambda x: len(x) > i)\n",
    "        depressingSkills , _ = trueSkillRate(TargetDf)\n",
    "        r1 = [k for k in depressingSkills if depressingSkills[k].mu > 25]\n",
    "        r2 = [k for k in depressingSkills if depressingSkills[k].mu < 25]\n",
    "        \n",
    "        TargetDf = numbers.filter(lambda x: len(x) > i+1) \n",
    "        depressingSkills , _ = trueSkillRate(TargetDf)\n",
    "        class1 = [k for k in depressingSkills if depressingSkills[k].mu > 25]\n",
    "        class2 = [k for k in depressingSkills if depressingSkills[k].mu < 25]\n",
    "        \n",
    "        \n",
    "        flips_root = len(set(root1).intersection(class2)) + len(set(root2).intersection(class1))\n",
    "        flips_consecutive = len(set(r1).intersection(class2)) + len(set(r2).intersection(class1))\n",
    "        print (\"Total class flips at threshold level %d from %d : %d , %d from root\" %(i,i+1,flips_consecutive , flips_root ))\n",
    "        rootflips.append(flips_root)\n",
    "        classflips.append(flips_consecutive)\n",
    "\n",
    "    return classflips , rootflips\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.838275Z",
     "start_time": "2017-08-16T09:27:06.817655Z"
    },
    "collapsed": true,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def linearDist( point1 , point2 ):\n",
    "    #radius of earth in meters\n",
    "    R=6378.137\n",
    "    #Coordinate offsets in radians\n",
    "    lat1 = radians(point1.y)\n",
    "    lon1 = radians(point1.x)\n",
    "    lat2 = radians(point2.y)\n",
    "    lon2 = radians(point2.x)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    absDist = R * c\n",
    "#     if absDist/10.0 < 1:\n",
    "#         distance = 10\n",
    "#     elif absDist/100.0 < 1:\n",
    "#         distance = 100\n",
    "#     elif absDist/500.0 < 1:\n",
    "#         distance = 500\n",
    "#     elif absDist/1000.0 < 1:\n",
    "#         distance = 1000\n",
    "#     else:\n",
    "#         distance = 5000\n",
    "        \n",
    "    return absDist\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.849964Z",
     "start_time": "2017-08-16T09:27:06.840464Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rollingFlips, rootFlips  = stabilityAnalysis(DimensionDF, 3 , 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:06.864736Z",
     "start_time": "2017-08-16T09:27:06.852154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _, ax1 = plt.subplots(figsize=(15, 10))\n",
    "# ax1.plot(range(4,13), rollingFlips  , 'b' )\n",
    "# ax1.plot(range(4,13) , rootFlips  , 'g')\n",
    "\n",
    "# ax1.set_xlabel('Votes Threshold', fontsize = 20)\n",
    "# ax1.set_ylabel('Samples that switch classes' , fontsize = 20)\n",
    "# plt.title(\"Trueskill Stability\" , fontsize = 20)\n",
    "# ax1.legend([\"Flips compared to last threshold\" , \"Flips compared to threshold of 4 votes\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:27:07.187833Z",
     "start_time": "2017-08-16T09:27:06.866895Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (16, 12)})\n",
    "sns.set(font_scale=1)  \n",
    "ax = sns.distplot(VotesDistribution )\n",
    "ax.set(xlabel='Votes', ylabel='Population')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the final Dataframe that we use for rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:34:40.307721Z",
     "start_time": "2017-08-16T09:34:30.511078Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TargetDf = numbers.filter(lambda x: len(x) > 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:34:42.130526Z",
     "start_time": "2017-08-16T09:34:42.103750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa_df = TargetDf[(TargetDf['left_id'].isin(us_poly_Ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:37:52.067577Z",
     "start_time": "2017-08-16T09:37:52.060066Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(set(usa_df['left_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:35:46.413527Z",
     "start_time": "2017-08-16T09:35:46.353903Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usa_df.to_csv(\"../streetview/easternCities2Votes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:44:57.655827Z",
     "start_time": "2017-08-16T09:44:57.652166Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fivevotes = pd.read_csv(\"../streetview/5votes.csv\")\n",
    "# len(fivevotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:38:02.060251Z",
     "start_time": "2017-08-16T09:38:02.029473Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(set(TargetDf['left_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:38:05.864026Z",
     "start_time": "2017-08-16T09:38:05.858492Z"
    }
   },
   "outputs": [],
   "source": [
    "len(TargetDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:38:08.957222Z",
     "start_time": "2017-08-16T09:38:08.924136Z"
    }
   },
   "outputs": [],
   "source": [
    "len(TargetDf[(TargetDf['winner'] == 'equal')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:38:11.545595Z",
     "start_time": "2017-08-16T09:38:11.541830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trueskill import Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:38:12.632115Z",
     "start_time": "2017-08-16T09:38:12.559460Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trueskill.backends import available_backends\n",
    "from trueskill import setup\n",
    "from mpmath import mp\n",
    "if 'mpmath' in available_backends():\n",
    "    # mpmath can be used in the current environment\n",
    "    setup(backend='mpmath')\n",
    "mp.dps = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:41:40.170075Z",
     "start_time": "2017-08-16T09:38:13.546221Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depressingSkills , depRatingTable = trueSkillRate(TargetDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:42:28.784236Z",
     "start_time": "2017-08-16T09:42:15.634967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter the final ratings based on the US city ids of images\n",
    "finalSkills = {}\n",
    "# leftids = list(set(TargetDf['left_id']))\n",
    "leftids = us_poly_Ids\n",
    "for k in depressingSkills:\n",
    "    if k in leftids:\n",
    "        finalSkills[k] = depressingSkills[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:46:55.951631Z",
     "start_time": "2017-08-16T09:46:55.935070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def doSampleTesting(skills , sampleSize, iters , distThresh):\n",
    "    median = []\n",
    "    variance = []\n",
    "    for i in range(iters):\n",
    "        sample = random.sample(skills.keys(),sampleSize)\n",
    "        deltaRating = []\n",
    "        for combo in combinations(sample, 2):\n",
    "            dist = linearDist(geometryDict[combo[0]] , geometryDict[combo[1]])\n",
    "            if dist < distThresh:\n",
    "                deltaRating.append(abs(skills[combo[0]].mu - skills[combo[1]].mu))\n",
    "        median.append(np.median(deltaRating))\n",
    "        variance.append(np.var(deltaRating))\n",
    "    return median , variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:46:57.928609Z",
     "start_time": "2017-08-16T09:46:57.924211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = random.sample(finalSkills.keys(),300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:47:00.875863Z",
     "start_time": "2017-08-16T09:46:58.498949Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "distances = []\n",
    "deltaRating = []\n",
    "# c= ipp.Client()\n",
    "for combo in combinations(sample, 2):\n",
    "    #d = c[0].apply_async(linearDist , geometryDict[combo[0]] , geometryDict[combo[1]])\n",
    "    dist = linearDist(geometryDict[combo[0]] , geometryDict[combo[1]])\n",
    "    if dist < 10:\n",
    "        distances.append(dist)\n",
    "        #delta = c[1].apply_async(abs ,(finalSkills[combo[0]].mu - finalSkills[combo[1]].mu))\n",
    "        deltaRating.append(abs(finalSkills[combo[0]].mu - finalSkills[combo[1]].mu))\n",
    "    \n",
    "    #distances.append(d)\n",
    "    #deltaRating.append(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:22.331907Z",
     "start_time": "2017-08-16T09:47:02.192595Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deltaMedians , deltaVar = doSampleTesting(finalSkills , 300 , 100 , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:22.337004Z",
     "start_time": "2017-08-16T09:50:22.333657Z"
    }
   },
   "outputs": [],
   "source": [
    "len(deltaMedians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:22.539888Z",
     "start_time": "2017-08-16T09:50:22.338531Z"
    }
   },
   "outputs": [],
   "source": [
    "#g = sns.jointplot(np.asarray(distances), np.asarray(deltaRating), kind=\"reg\")\n",
    "ax = sns.distplot(deltaMedians)\n",
    "ax = sns.distplot(deltaVar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:30.168375Z",
     "start_time": "2017-08-16T09:50:30.161088Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(set(finalSkills.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:35.068074Z",
     "start_time": "2017-08-16T09:50:35.062400Z"
    }
   },
   "outputs": [],
   "source": [
    "depRatingTable[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:46.743518Z",
     "start_time": "2017-08-16T09:50:46.740236Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rated_depSkills = rate(depRatingTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:50:47.543958Z",
     "start_time": "2017-08-16T09:50:47.539472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skill = {}\n",
    "# for s in rated_depSkills:\n",
    "#     for k in s:\n",
    "#         if k in skill:\n",
    "#             skill[k].append(s[k])\n",
    "#         else:\n",
    "#             skill[k] = []\n",
    "#             skill[k].append(s[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:20.920113Z",
     "start_time": "2017-08-16T09:51:20.883972Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorted by plain pairvise matches\n",
    "sortedImagesSkillsMu = sorted(finalSkills, key=lambda k: depressingSkills[k].mu)\n",
    "sortedImagesSkillsSigma = sorted(finalSkills, key=lambda k: depressingSkills[k].sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:21.621995Z",
     "start_time": "2017-08-16T09:51:21.618913Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorted by ranking tables\n",
    "# sortedImages =  sorted(skill, key=lambda k: skill[k][-1].mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:21.909725Z",
     "start_time": "2017-08-16T09:51:21.906828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sortedImagesByVar =  sorted(skill, key=lambda k: skill[k][-1].sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:22.337002Z",
     "start_time": "2017-08-16T09:51:22.333762Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skill[sortedImages[-1]][0].mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:22.761312Z",
     "start_time": "2017-08-16T09:51:22.757791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorted by ranking tables\n",
    "# imgid = sortedImages[-500]\n",
    "# Image(imgDir + imgid + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:23.324669Z",
     "start_time": "2017-08-16T09:51:23.314924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPointMapping(df):\n",
    "    geometryDict = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['left_id'] not in geometryDict:\n",
    "            geometryDict[row['left_id']] = Point((row['left_lat'] , row['left_long']))\n",
    "        if row['right_id'] not in geometryDict:\n",
    "            geometryDict[row['right_id']] = Point((row['right_lat'] , row['right_long']))\n",
    "    return geometryDict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:24.055357Z",
     "start_time": "2017-08-16T09:51:24.050123Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sortedImagesSkillsMu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:43.937506Z",
     "start_time": "2017-08-16T09:51:43.915222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sorted by plain pairvise matches\n",
    "imgid = sortedImagesSkillsMu[-2]\n",
    "Image(imgDir + imgid + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:46.589332Z",
     "start_time": "2017-08-16T09:51:46.586079Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dir(rated_depSkills[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:57.350173Z",
     "start_time": "2017-08-16T09:51:57.336548Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skillMeans = [finalSkills[k].mu for k in finalSkills]\n",
    "#skillMeans = [depressingSkills[k].mu for k in depressingSkills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:57.754662Z",
     "start_time": "2017-08-16T09:51:57.750908Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSkill= np.max(skillMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:51:58.979175Z",
     "start_time": "2017-08-16T09:51:58.974625Z"
    }
   },
   "outputs": [],
   "source": [
    "print (maxSkill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:52:25.992099Z",
     "start_time": "2017-08-16T09:52:25.979035Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skillSigmas = [finalSkills[k].sigma for k in finalSkills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:52:28.707237Z",
     "start_time": "2017-08-16T09:52:28.704041Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sigmas = [skill[k][-1].sigma for k in skill]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:52:29.210118Z",
     "start_time": "2017-08-16T09:52:28.951658Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (16, 12)})\n",
    "sns.set(font_scale=1) \n",
    "# ax = sns.distplot(skillMeans , hist_kws=dict(cumulative=True), kde_kws=dict(cumulative=True) )\n",
    "ax = sns.distplot(skillMeans )\n",
    "ax.set(xlabel='Score', ylabel='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:53:25.638693Z",
     "start_time": "2017-08-16T09:53:25.615813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selectedDf = dict((k, [finalSkills[k].mu ]) for k in finalSkills if (finalSkills[k].mu < 22 or finalSkills[k].mu > 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:53:27.033599Z",
     "start_time": "2017-08-16T09:53:27.030201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selectedDf = dict((k, [depressingSkills[k].mu ]) for k in depressingSkills if (depressingSkills[k].mu < 17 or depressingSkills[k].mu > 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:53:30.862642Z",
     "start_time": "2017-08-16T09:53:30.856964Z"
    }
   },
   "outputs": [],
   "source": [
    "len(selectedDf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:54:27.831580Z",
     "start_time": "2017-08-16T09:54:27.800445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDf = {}\n",
    "for k in selectedDf:\n",
    "    path = imgDir + k + \".jpg\"\n",
    "    if selectedDf[k][0] > 28:\n",
    "        d = {'key':k , 'trueSkill' : selectedDf[k] , 'label' : 1 , 'path' : path}\n",
    "    elif selectedDf[k][0] < 22:\n",
    "        d = {'key':k , 'trueSkill' : selectedDf[k] , 'label' : 0 , 'path' : path}\n",
    "    else:\n",
    "        continue\n",
    "    testDf[k] = dict()\n",
    "    testDf[k] = d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fringeDf = {}\n",
    "# for k in selectedDf:\n",
    "#     path = imgDir + k + \".jpg\"\n",
    "#     if selectedDf[k][0] <19 :\n",
    "#         d = {'key':k , 'trueSkill' : selectedDf[k] , 'label' : 0 , 'path' : path}\n",
    "#     elif selectedDf[k][0] > 33:\n",
    "#         d = {'key':k , 'trueSkill' : selectedDf[k] , 'label' : 1 , 'path' : path}\n",
    "#     else:\n",
    "#         continue\n",
    "#     fringeDf[k] = dict()\n",
    "#     fringeDf[k] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:54:29.795307Z",
     "start_time": "2017-08-16T09:54:29.789972Z"
    }
   },
   "outputs": [],
   "source": [
    "len(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T09:55:32.381113Z",
     "start_time": "2017-08-16T09:55:32.243675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('../Data/cityDf.pkl', 'wb') as handle:\n",
    "#     pickle.dump(testDf, handle , protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T17:22:45.049636Z",
     "start_time": "2017-08-14T17:22:45.036839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampledFringe = random.sample( testDf.items(), 5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T17:32:31.286596Z",
     "start_time": "2017-08-14T17:32:31.280944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampledFringe[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T17:22:54.111354Z",
     "start_time": "2017-08-14T17:22:54.100734Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels = [sampledFringe[i][1]['label'] for i in range(len(sampledFringe))]\n",
    "# np.sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-14T17:32:39.930297Z",
     "start_time": "2017-08-14T17:32:39.728217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('../Data/testImages.pkl', 'wb') as handle:\n",
    "#     segnetLabels = pickle.dump(sampledFringe, handle , protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T11:11:46.728890Z",
     "start_time": "2017-08-02T11:11:46.714656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgid = selectedDf.keys()[-100]\n",
    "#imgid = \"51422739fdc9f04926008637\"\n",
    "Image(imgDir + imgid + \".jpg\")\n",
    "#print( selectedDf[selectedDf.keys()[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T15:59:22.818390Z",
     "start_time": "2017-07-28T15:59:22.813030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(selectedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-28T15:59:28.829458Z",
     "start_time": "2017-07-28T15:59:24.979801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtSkills = dict((k, depressingSkills[k]) for k in depressingSkills if k in us_poly_Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.143976Z",
     "start_time": "2017-07-26T13:31:23.135866Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"beautyKeys.txt\", \"w\") as f:\n",
    "#     for key in depressingSkills:\n",
    "#         f.write(key+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.155245Z",
     "start_time": "2017-07-26T13:31:23.145596Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtSkills.keys()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.171466Z",
     "start_time": "2017-07-26T13:31:23.156870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skillsCity = [filtSkills[i].mu for i in filtSkills]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:59:25.897948Z",
     "start_time": "2017-07-26T14:59:25.640817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (16, 12)})\n",
    "sns.set(font_scale=1) \n",
    "# ax = sns.distplot(skillMeans , hist_kws=dict(cumulative=True), kde_kws=dict(cumulative=True) )\n",
    "ax = sns.distplot(skillsCity )\n",
    "ax.set(xlabel='Score', ylabel='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.389450Z",
     "start_time": "2017-07-26T13:31:23.387260Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(means )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.624518Z",
     "start_time": "2017-07-26T13:31:23.391011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(sigmas ,kde_kws={\"color\": \"b\", \"lw\": 2, \"label\": \"Paiwise Trueskill Std. Deviation\"} )\n",
    "sns.distplot(skillSigmas , kde_kws={\"color\": \"g\", \"lw\": 2, \"label\": \"Ranked table Trueskill Std. Deviation\"},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.628481Z",
     "start_time": "2017-07-26T13:31:23.626280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qdf = numbers.filter(lambda x: len(x) > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.666563Z",
     "start_time": "2017-07-26T13:31:23.630191Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def QscoreRating(df):\n",
    "    W = {}\n",
    "    L = {}\n",
    "    win = {}\n",
    "    loose = {}\n",
    "    contest = {}\n",
    "    rating = {}\n",
    "    for index, row in df.iterrows():\n",
    "        if row['left_id'] not in contest:\n",
    "            contest[row['left_id']] = 0\n",
    "            \n",
    "            win[row['left_id']] = {}\n",
    "            win[row['left_id']]['w'] = 0\n",
    "            win[row['left_id']]['loosers'] = []\n",
    "            \n",
    "            loose[row['left_id']] = {}\n",
    "            loose[row['left_id']]['l'] = 0 \n",
    "            loose[row['left_id']]['winners'] = []\n",
    "            \n",
    "            W[row['left_id']] =0.0\n",
    "            L[row['left_id']] =0.0\n",
    "        \n",
    "        contest[row['left_id']]+=1\n",
    "        \n",
    "        if row['winner'] == 'left':\n",
    "            win[row['left_id']]['w'] += 1\n",
    "            win[row['left_id']]['loosers'].append(row['right_id'])\n",
    "\n",
    "        if row['winner'] == 'right':\n",
    "            loose[row['left_id']]['l'] += 1\n",
    "            loose[row['left_id']]['winners'].append(row['right_id'])\n",
    "        \n",
    "    for k in win:\n",
    "        W[k] = float(win[k]['w'])/float(contest[k])\n",
    "        \n",
    "    for k in loose:\n",
    "        L[k] = float(loose[k]['l'])/float(contest[k])\n",
    "    \n",
    "    for k in contest:\n",
    "        S1 = sum([W.get(i,0) for i in win[k]['loosers']])\n",
    "        S2 = sum([L.get(i,0) for i in loose[k]['winners']])\n",
    "        if S1 == 0:\n",
    "            S1 = 0.0\n",
    "        else:\n",
    "            S1 = float(S1)/float(win[k]['w'])\n",
    "        \n",
    "        if S2 == 0:\n",
    "            S2 = 0.0\n",
    "        else:\n",
    "            S2 = float(S2)/float(loose[k]['l'])\n",
    "        \n",
    "        r = (10.0/3.0)*(W[k] + S1 - S2 + 1)\n",
    "        rating[k] = r\n",
    "    return rating\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.678466Z",
     "start_time": "2017-07-26T13:31:23.668323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qscores = QscoreRating(Qdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.686748Z",
     "start_time": "2017-07-26T13:31:23.680082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(set(Qdf['left_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.693155Z",
     "start_time": "2017-07-26T13:31:23.688491Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finalQ = {}\n",
    "# for index, row in TargetDf.iterrows():\n",
    "#     finalQ[row['left_id']] = Qscores[row['left_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.701104Z",
     "start_time": "2017-07-26T13:31:23.694568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(finalQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.707131Z",
     "start_time": "2017-07-26T13:31:23.702693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={\"figure.figsize\": (16, 12)})\n",
    "# sns.distplot(finalQ.values() )\n",
    "# #sns.distplot(finalQ.values() , hist_kws=dict(cumulative=True), kde_kws=dict(cumulative=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.716492Z",
     "start_time": "2017-07-26T13:31:23.708552Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sortedSimple =  sorted(finalQ, key=lambda k: finalQ[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.726739Z",
     "start_time": "2017-07-26T13:31:23.718963Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(sortedSimple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.736699Z",
     "start_time": "2017-07-26T13:31:23.729197Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imgid = sortedSimple[3500]\n",
    "# # imgid = \"50f43ba4fdc9f065f000326b\"\n",
    "# Image(imgDir + imgid + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.914280Z",
     "start_time": "2017-07-26T13:31:23.739088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "caffe_root = '/work/sagarj/caffe-rc5/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "from caffe.proto import caffe_pb2\n",
    "import lmdb\n",
    "\n",
    "#Size of images\n",
    "IMAGE_WIDTH = 227\n",
    "IMAGE_HEIGHT = 227\n",
    "\n",
    "def transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT):\n",
    "\n",
    "    #Histogram Equalization\n",
    "    img[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n",
    "    img[:, :, 1] = cv2.equalizeHist(img[:, :, 1])\n",
    "    img[:, :, 2] = cv2.equalizeHist(img[:, :, 2])\n",
    "\n",
    "    #Image Resizing\n",
    "    img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def make_datum(img, label):\n",
    "    #image is numpy.ndarray format. BGR instead of RGB\n",
    "    return caffe_pb2.Datum(\n",
    "        channels=3,\n",
    "        width=IMAGE_WIDTH,\n",
    "        height=IMAGE_HEIGHT,\n",
    "        label=label,\n",
    "        data=np.rollaxis(img, 2).tostring())\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:23.920382Z",
     "start_time": "2017-07-26T13:31:23.916224Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testKeys = random.sample(list(finalSkills.keys()), int(0.2*len(finalSkills.keys())))\n",
    "#testKeys = random.sample(list(depressingSkills.keys()), int(0.2*len(depressingSkills.keys())))\n",
    "#testKeys = random.sample(list(filtSkills.keys()), int(0.15*len(filtSkills.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:24.073037Z",
     "start_time": "2017-07-26T13:31:23.922031Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainKeys = [k for k in finalSkills.keys() if k not in testKeys]\n",
    "#trainKeys = [k for k in depressingSkills.keys() if k not in testKeys]\n",
    "#trainKeys = [k for k in filtSkills.keys() if k not in testKeys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T13:31:24.081507Z",
     "start_time": "2017-07-26T13:31:24.075087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(set(trainKeys).intersection(testKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:36.220480Z",
     "start_time": "2017-07-26T14:57:36.214670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(testKeys) , len(trainKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:39.155926Z",
     "start_time": "2017-07-26T14:57:38.781183Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "train_data = {}\n",
    "for k in trainKeys:\n",
    "    src = [imgDir + k + \".jpg\"]\n",
    "    if not os.path.exists(src[0]):\n",
    "        continue\n",
    "    else:\n",
    "        if os.path.exists(AugDir + k):\n",
    "            images = os.listdir(AugDir + k)\n",
    "            random.shuffle(images)\n",
    "            for i in images[:20]:\n",
    "                src.append(AugDir + k + \"/\" + i)\n",
    "        train_data[k] = src\n",
    "        \n",
    "test_data = {}\n",
    "for k in testKeys:\n",
    "    src = [imgDir + k + \".jpg\"]\n",
    "    if not os.path.exists(src[0]):\n",
    "        continue\n",
    "    else:\n",
    "        if os.path.exists(AugDir + k):\n",
    "            images = os.listdir(AugDir + k)\n",
    "            random.shuffle(images)\n",
    "            for i in images[:20]:\n",
    "                src.append(AugDir + k + \"/\" + i)\n",
    "        test_data[k] = src\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:39.894738Z",
     "start_time": "2017-07-26T14:57:39.888873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_data) , len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:41.129412Z",
     "start_time": "2017-07-26T14:57:41.124676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = random.sample(train_data.keys(), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:45.559677Z",
     "start_time": "2017-07-26T14:57:45.555519Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augTest = {}\n",
    "# for k in s: \n",
    "#     if len(train_data[k]) > 1:\n",
    "#         augTest[k] = train_data[k]\n",
    "# save_obj(augTest , \"sampledAugment.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T14:57:50.757753Z",
     "start_time": "2017-07-26T14:57:50.750544Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[train_data.keys()[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test path files for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T00:00:28.206181Z",
     "start_time": "2017-07-26T00:00:28.194997Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ImageList = \"../Data/TrainImageListBinary_augmented.txt\"\n",
    "# label = 0\n",
    "# for in_idx, (k, img_path) in enumerate(train_data.items()):\n",
    "#     val = int(depressingSkills[k].mu)\n",
    "# #     if val < 23:\n",
    "# #         label = 0\n",
    "# #     elif val > 22 and val < 29:\n",
    "# #         label = 1\n",
    "# #     elif val > 28:\n",
    "# #         label = 2\n",
    "#     if val < 21:\n",
    "#         label = 0\n",
    "#     elif val > 29:\n",
    "#         label = 1\n",
    "#     else:\n",
    "#         continue\n",
    "#     with open(ImageList,'a') as f:\n",
    "#         for p in img_path:\n",
    "#             f.write(p + \",\" + str(label) + \"\\n\")\n",
    "\n",
    "# ImageList = \"../Data/TestImageListBinary_augmented.txt\"\n",
    "# label = 0\n",
    "# for in_idx, (k, img_path) in enumerate(test_data.items()):\n",
    "#     val = int(depressingSkills[k].mu)\n",
    "# #     if val < 23:\n",
    "# #         label = 0\n",
    "# #     elif val > 22 and val < 29:\n",
    "# #         label = 1\n",
    "# #     elif val > 28:\n",
    "# #         label = 2\n",
    "#     if val < 21:\n",
    "#         label = 0\n",
    "#     elif val > 29:\n",
    "#         label = 1\n",
    "#     else:\n",
    "#         continue\n",
    "#     with open(ImageList,'a') as f:\n",
    "#         for p in img_path:\n",
    "#             f.write(p + \",\" + str(label) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMDB creation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T16:48:04.364185Z",
     "start_time": "2017-07-26T16:48:04.359692Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lmdb = '../Data/train_lmdb_beauty_augmented_sparse'\n",
    "validation_lmdb = '../Data/validation_lmdb_beauty_augmented_sparse'\n",
    "log = \"lmdblogs.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-26T16:53:56.729781Z",
     "start_time": "2017-07-26T16:48:05.399954Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print ('Creating train_lmdb')\n",
    "# f = open(log,'w')\n",
    "# in_db = lmdb.open(train_lmdb, map_size=int(1e12))\n",
    "# with in_db.begin(write=True) as in_txn:\n",
    "#     for in_idx, (k, img_path) in enumerate(train_data.items()):\n",
    "#         val = int(depressingSkills[k].mu)\n",
    "#         label = 0\n",
    "# #         if val < 22.0:\n",
    "# #             label = 0\n",
    "# #         elif val >= 22.0 and val < 30.0:\n",
    "# #             label = 1\n",
    "# #         elif val >= 30.0:\n",
    "# #             label = 2\n",
    "        \n",
    "#         if val < 20.0:\n",
    "#             label = 0\n",
    "#         elif val > 30.0:\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             continue\n",
    "#         for p in img_path:\n",
    "#             img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "#             img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "#             datum = make_datum(img, label)\n",
    "#             in_txn.put('{:0>5d}'.format(in_idx), datum.SerializeToString())\n",
    "#             line = '{:0>5d}'.format(in_idx) + ':' + p + \"\\n\"\n",
    "#             f.write(line)\n",
    "# in_db.close()\n",
    "\n",
    "\n",
    "# print ('\\nCreating validation_lmdb')\n",
    "\n",
    "# in_db = lmdb.open(validation_lmdb, map_size=int(1e12))\n",
    "# with in_db.begin(write=True) as in_txn:\n",
    "#     for in_idx, (k, img_path) in enumerate(test_data.items()):\n",
    "        \n",
    "#         val = int(depressingSkills[k].mu)\n",
    "#         label = 0\n",
    "#         label = 0\n",
    "# #         if val < 22.0:\n",
    "# #             label = 0\n",
    "# #         elif val >= 22.0 and val < 30.0:\n",
    "# #             label = 1\n",
    "# #         elif val >= 30.0:\n",
    "# #             label = 2\n",
    "            \n",
    "#         if val < 20.0:\n",
    "#             label = 0\n",
    "#         elif val > 30.0:\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "#         for p in img_path:\n",
    "#             img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
    "#             img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "#             datum = make_datum(img, label)\n",
    "#             in_txn.put('{:0>5d}'.format(in_idx), datum.SerializeToString())\n",
    "#             line = '{:0>5d}'.format(in_idx) + ':' + p + \"\\n\"\n",
    "#             f.write(line)\n",
    "# in_db.close()\n",
    "# f.close()\n",
    "# print ('\\nFinished processing all images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HD5 creation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract mean from the mean image file\n",
    "# mean_file_binaryproto = '../Data/Safety8Mean.binaryproto' # Mean image file\n",
    "# mean_blobproto_new = caffe.proto.caffe_pb2.BlobProto()\n",
    "# f = open(mean_file_binaryproto, 'rb')\n",
    "# mean_blobproto_new.ParseFromString(f.read())\n",
    "# mean_image = caffe.io.blobproto_to_array(mean_blobproto_new)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:03.338028Z",
     "start_time": "2017-07-21T10:03:03.329082Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_test = []\n",
    "# labels = []\n",
    "# BatchSize = 5000\n",
    "\n",
    "# for in_idx, (k, img_path) in enumerate(test_data.items()):\n",
    "#     img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "#     img = np.rollaxis(img, 2) - mean_image\n",
    "#     dataset_test.append(img)\n",
    "#     labels.append(float(depressingSkills[k].mu / maxSkill))\n",
    "\n",
    "    \n",
    "# dataset_t = np.stack(dataset_test,axis = 0)\n",
    "# dataset_t = np.squeeze(dataset_t, axis=1)\n",
    "# labels = np.asarray(labels)\n",
    "\n",
    "# i = 0\n",
    "# DIR = \"/work/sagarj/Work/BellLabs/Data/h5Data/\"\n",
    "\n",
    "# text_fn = os.path.join(DIR, 'test_SafetyRegression.txt')\n",
    "# for start, end in zip(range(0, len(dataset_t), BatchSize), range(BatchSize, len(dataset_t), BatchSize)):\n",
    "    \n",
    "#     h5_fn = DIR+'test_SafetyRegression' + str(i) +'.h5'\n",
    "#     with h5py.File(h5_fn, 'w') as f:\n",
    "#         f['data'] = dataset_t[start:end]\n",
    "#         f['label'] = labels[start:end]\n",
    "        \n",
    "#     with open(text_fn, 'a') as f:\n",
    "#         print(h5_fn, file = f)\n",
    "#     i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:03.717897Z",
     "start_time": "2017-07-21T10:03:03.714413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_t.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:04.445256Z",
     "start_time": "2017-07-21T10:03:04.436553Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_test = []\n",
    "# labels = []\n",
    "# BatchSize = 5000\n",
    "\n",
    "\n",
    "# for in_idx, (k, img_path) in enumerate(train_data.items()):\n",
    "#     img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     img = transform_img(img, img_width=IMAGE_WIDTH, img_height=IMAGE_HEIGHT)\n",
    "#     img = np.rollaxis(img, 2) - mean_image\n",
    "#     dataset_test.append(img)\n",
    "#     labels.append(float(depressingSkills[k].mu / maxSkill))\n",
    "\n",
    "\n",
    "# dataset_t = np.stack(dataset_test,axis = 0)\n",
    "# dataset_t = np.squeeze(dataset_t, axis=1)\n",
    "# labels = np.asarray(labels)\n",
    "# i = 0\n",
    "# DIR = \"/work/sagarj/Work/BellLabs/Data/h5Data/\"\n",
    "# text_fn = os.path.join(DIR, 'train_SafetyRegression.txt')\n",
    "# for start, end in zip(range(0, len(dataset_t), BatchSize), range(BatchSize, len(dataset_t), BatchSize)):\n",
    "    \n",
    "#     h5_fn = DIR+'train_SafetyRegression' + str(i) +'.h5'\n",
    "#     with h5py.File(h5_fn, 'w') as f:\n",
    "#         f['data'] = dataset_t[start:end]\n",
    "#         f['label'] = labels[start:end]\n",
    "        \n",
    "#     with open(text_fn, 'a') as f:\n",
    "#         print(h5_fn, file = f)\n",
    "#     i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:05.310673Z",
     "start_time": "2017-07-21T10:03:05.307186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset_t.shape , labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:05.598914Z",
     "start_time": "2017-07-21T10:03:05.595495Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.distplot(labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Logic for moving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:06.483325Z",
     "start_time": "2017-07-21T10:03:06.479167Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# curatedDir = \"../streetview/RankedDepress_4/\"\n",
    "# beauty = \"1/\"\n",
    "# notBeauty = \"0/\"\n",
    "# train = curatedDir + \"train/\"\n",
    "# test = curatedDir + \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:07.032719Z",
     "start_time": "2017-07-21T10:03:07.029286Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:07.672365Z",
     "start_time": "2017-07-21T10:03:07.665498Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Move Train SEtL \n",
    "\n",
    "# for k in trainKeys:\n",
    "#     src = imgDir + k + \".jpg\"\n",
    "#     if not os.path.exists(src):\n",
    "#         continue\n",
    "#     if depressingSkills[k].mu > 25:\n",
    "#         destDir = curatedDir + train + beauty \n",
    "#         if not os.path.exists(os.path.dirname(destDir)):\n",
    "#             os.makedirs(os.path.dirname(destDir))\n",
    "#         dest = destDir+ k + \".jpg\"\n",
    "#         copyfile(src , dest)\n",
    "    \n",
    "#     if depressingSkills[k].mu < 25:\n",
    "#         destDir = curatedDir + train + notBeauty \n",
    "#         if not os.path.exists(os.path.dirname(destDir)):\n",
    "#             os.makedirs(os.path.dirname(destDir))\n",
    "#         dest = destDir + k + \".jpg\"\n",
    "#         copyfile(src , dest)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T10:03:08.429918Z",
     "start_time": "2017-07-21T10:03:08.423191Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move test\n",
    "\n",
    "# for k in keys:\n",
    "#     src = imgDir + k + \".jpg\"\n",
    "#     if not os.path.exists(src):\n",
    "#         continue\n",
    "#     if depressingSkills[k].mu > 25:\n",
    "#         destDir = curatedDir + test + beauty \n",
    "#         if not os.path.exists(os.path.dirname(destDir)):\n",
    "#             os.makedirs(os.path.dirname(destDir))\n",
    "#         dest = destDir+ k + \".jpg\"\n",
    "#         copyfile(src , dest)\n",
    "    \n",
    "#     if depressingSkills[k].mu < 25:\n",
    "#         destDir = curatedDir + test + notBeauty \n",
    "#         if not os.path.exists(os.path.dirname(destDir)):\n",
    "#             os.makedirs(os.path.dirname(destDir))\n",
    "#         dest = destDir + k + \".jpg\"\n",
    "#         copyfile(src , dest)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
